{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from numpy.ma.core import ceil\n",
    "from scipy.spatial import distance #distance calculation\n",
    "from sklearn.preprocessing import MinMaxScaler #normalisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score #scoring\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation, colors\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: ['Magnitude Spectrum Overall Standard Deviation', 'Power Spectrum Overall Standard Deviation', 'Spectral Centroid Overall Standard Deviation', 'Zero Crossings Overall Standard Deviation', 'Derivative of Zero Crossings Overall Standard Deviation', 'Standard Deviation of Zero Crossings Overall Standard Deviation', 'Derivative of Running Mean of Zero Crossings Overall Standard Deviation', 'Derivative of Standard Deviation of Zero Crossings Overall Standard Deviation', 'Beat Histogram Overall Standard Deviation', 'Strongest Beat Overall Standard Deviation', 'Derivative of Strongest Beat Overall Standard Deviation', 'Running Mean of Strongest Beat Overall Standard Deviation', 'Derivative of Running Mean of Strongest Beat Overall Standard Deviation', 'Beat Sum Overall Standard Deviation', 'Derivative of Beat Sum Overall Standard Deviation', 'Running Mean of Beat Sum Overall Standard Deviation', 'Derivative of Running Mean of Beat Sum Overall Standard Deviation', 'Standard Deviation of Strongest Frequency Via Zero Crossings Overall Standard Deviation', 'Derivative of Running Mean of Strongest Frequency Via Zero Crossings Overall Standard Deviation', 'Derivative of Standard Deviation of Strongest Frequency Via Zero Crossings Overall Standard Deviation', 'Strongest Frequency Via Spectral Centroid Overall Standard Deviation', 'Derivative of Strongest Frequency Via Spectral Centroid Overall Standard Deviation', 'Standard Deviation of Strongest Frequency Via Spectral Centroid Overall Standard Deviation', 'Derivative of Running Mean of Strongest Frequency Via Spectral Centroid Overall Standard Deviation', 'Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'Derivative of Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'Running Mean of Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'Standard Deviation of Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'Derivative of Running Mean of Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'Derivative of Standard Deviation of Strongest Frequency Via FFT Maximum Overall Standard Deviation', 'MFCC Overall Standard Deviation', 'Derivative of MFCC Overall Standard Deviation', 'Standard Deviation of MFCC Overall Standard Deviation', 'Derivative of Running Mean of MFCC Overall Standard Deviation', 'Derivative of Standard Deviation of MFCC Overall Standard Deviation', 'Derivative of Standard Deviation of LPC Overall Standard Deviation', 'Peak Detection Overall Standard Deviation', 'Partial Based Spectral Centroid Overall Standard Deviation', 'Running Mean of Partial Based Spectral Centroid Overall Standard Deviation', 'Standard Deviation of Partial Based Spectral Centroid Overall Standard Deviation', 'Derivative of Running Mean of Partial Based Spectral Centroid Overall Standard Deviation', 'Derivative of Standard Deviation of Partial Based Spectral Centroid Overall Standard Deviation', 'Derivative of Peak Based Spectral Smoothness Overall Standard Deviation', 'Standard Deviation of Peak Based Spectral Smoothness Overall Standard Deviation', 'Derivative of Running Mean of Peak Based Spectral Smoothness Overall Standard Deviation', 'Derivative of Standard Deviation of Peak Based Spectral Smoothness Overall Standard Deviation', 'Relative Difference Function Overall Standard Deviation', 'Derivative of Relative Difference Function Overall Standard Deviation', 'Running Mean of Relative Difference Function Overall Standard Deviation', 'Derivative of Running Mean of Relative Difference Function Overall Standard Deviation', 'Derivative of Standard Deviation of Relative Difference Function Overall Standard Deviation', 'Magnitude Spectrum Overall Average', 'Power Spectrum Overall Average', 'FFT Bin Frequency Labels Overall Average', 'Spectral Centroid Overall Average', 'Derivative of Spectral Centroid Overall Average', 'Running Mean of Spectral Centroid Overall Average', 'Standard Deviation of Spectral Centroid Overall Average', 'Derivative of Running Mean of Spectral Centroid Overall Average', 'Standard Deviation of Spectral Rolloff Point Overall Average', 'Derivative of Standard Deviation of Spectral Rolloff Point Overall Average', 'Spectral Flux Overall Average', 'Running Mean of Spectral Flux Overall Average', 'Standard Deviation of Spectral Flux Overall Average', 'Derivative of Running Mean of Spectral Flux Overall Average', 'Derivative of Standard Deviation of Spectral Flux Overall Average', 'Compactness Overall Average', 'Derivative of Compactness Overall Average', 'Running Mean of Compactness Overall Average', 'Derivative of Running Mean of Compactness Overall Average', 'Standard Deviation of Spectral Variability Overall Average', 'Standard Deviation of Zero Crossings Overall Average', 'Derivative of Running Mean of Zero Crossings Overall Average', 'Standard Deviation of Strongest Beat Overall Average', 'Derivative of Running Mean of Strongest Beat Overall Average', 'Derivative of Standard Deviation of Strongest Beat Overall Average', 'Beat Sum Overall Average', 'Derivative of Beat Sum Overall Average', 'Running Mean of Beat Sum Overall Average', 'Derivative of Running Mean of Beat Sum Overall Average', 'Derivative of Standard Deviation of Beat Sum Overall Average', 'Running Mean of Strength Of Strongest Beat Overall Average', 'Strongest Frequency Via Zero Crossings Overall Average', 'Derivative of Strongest Frequency Via Zero Crossings Overall Average', 'Running Mean of Strongest Frequency Via Zero Crossings Overall Average', 'Derivative of Running Mean of Strongest Frequency Via Zero Crossings Overall Average', 'Derivative of Standard Deviation of Strongest Frequency Via Zero Crossings Overall Average', 'Strongest Frequency Via Spectral Centroid Overall Average', 'Derivative of Strongest Frequency Via Spectral Centroid Overall Average', 'Running Mean of Strongest Frequency Via Spectral Centroid Overall Average', 'Derivative of Running Mean of Strongest Frequency Via Spectral Centroid Overall Average', 'Derivative of Standard Deviation of Strongest Frequency Via Spectral Centroid Overall Average', 'Strongest Frequency Via FFT Maximum Overall Average', 'Running Mean of Strongest Frequency Via FFT Maximum Overall Average', 'Derivative of Running Mean of Strongest Frequency Via FFT Maximum Overall Average', 'Standard Deviation of MFCC Overall Average', 'Derivative of Running Mean of MFCC Overall Average', 'Derivative of Method of Moments Overall Average', 'Derivative of Running Mean of Method of Moments Overall Average', 'Peak Detection Overall Average', 'Partial Based Spectral Centroid Overall Average', 'Standard Deviation of Peak Based Spectral Smoothness Overall Average', 'Derivative of Running Mean of Peak Based Spectral Smoothness Overall Average', 'Derivative of Standard Deviation of Relative Difference Function Overall Average', 'Log of ConstantQ Overall Average']\n",
      "MAMAAA: 105\n",
      "105\n",
      "[[ 1.14319500e-03  1.67709620e-02  5.46800000e+00 ...  2.54800000e-03\n",
      "   3.21800000e-04 -5.00000000e+01]\n",
      " [ 2.61382600e-03  6.46369740e-02  1.24300000e+01 ... -3.47200000e-03\n",
      "   1.45200000e-04 -5.00000000e+01]\n",
      " [ 5.38002500e-03  1.89173582e-01  1.47400000e+01 ...  6.48600000e-03\n",
      "  -1.29900000e-03 -5.00000000e+01]\n",
      " ...\n",
      " [ 3.00439600e-03  6.67014880e-02  1.42700000e+01 ...  1.15200000e-03\n",
      "   1.79800000e-04 -5.00000000e+01]\n",
      " [ 1.09967000e-03  8.05048500e-03  1.55400000e+01 ...  1.06800000e-02\n",
      "  -1.49200000e-04 -5.00000000e+01]\n",
      " [ 2.31249000e-03  3.73964570e-02  2.26100000e+01 ...  1.47600000e-03\n",
      "   2.14000000e-04 -5.00000000e+01]]\n",
      "Standard:\n",
      "[[-0.59003684 -0.42122352 -1.12127663 ...  0.08545419  0.37453402\n",
      "   0.        ]\n",
      " [ 1.03640095  1.1240319   0.32891372 ... -1.55111616  0.30162488\n",
      "   0.        ]\n",
      " [ 4.09566639  5.14443931  0.81008863 ...  1.15602131 -0.29461177\n",
      "   0.        ]\n",
      " ...\n",
      " [ 1.4683501   1.19068048  0.71218724 ... -0.29405614  0.31590945\n",
      "   0.        ]\n",
      " [-0.63817312 -0.70274613  0.97672929 ...  2.29618345  0.18008211\n",
      "   0.        ]\n",
      " [ 0.70313975  0.24462802  2.44941613 ... -0.20597495  0.33002889\n",
      "   0.        ]]\n",
      "62\n"
     ]
    }
   ],
   "source": [
    "### MODIFY THE NAME OF YOUR CSV HERE\n",
    "df_data = pd.read_csv('y.csv')\n",
    "y = df_data['Navarasa']\n",
    "columns_to_drop = ['data_set_id', 'Cluster', 'Srno', 'Belonging to C-0', 'Belonging to C-1', 'Navarasa', 'sno']\n",
    "\n",
    "# extra_features_to_drop = ['Magnitude Spectrum Overall Standard Deviation', 'Magnitude Spectrum Overall Average',\n",
    "# \t\t\t\t\t\t  'Power Spectrum Overall Standard Deviation', 'Power Spectrum Overall Average',\n",
    "# \t\t\t\t\t\t  'FFT Bin Frequency Labels Overall Average', 'Beat Histogram Overall Standard Deviation',\n",
    "# \t\t\t\t\t\t  'Log of ConstantQ Overall Average', 'Spectral Centroid Overall Standard Deviation',\n",
    "# \t\t\t\t\t\t  'Peak Detection Overall Standard Deviation', 'Derivative of Method of Moments Overall Average', 'Derivative of Running Mean of Method of Moments Overall Average']\n",
    "\n",
    "# 11 / 13\n",
    "extra_features_to_drop = ['Magnitude Spectrum Overall Average','Power Spectrum Overall Standard Deviation', 'Power Spectrum Overall Average',\n",
    "\t\t\t\t\t\t   'Spectral Centroid Overall Standard Deviation','Derivative of Method of Moments Overall Average', 'Derivative of Running Mean of Method of Moments Overall Average']\n",
    "\n",
    "# 12 / 13\n",
    "extra_features_to_drop = ['Magnitude Spectrum Overall Standard Deviation', 'Magnitude Spectrum Overall Average',\n",
    "\t\t\t\t\t\t  'Power Spectrum Overall Standard Deviation', 'Power Spectrum Overall Average',\n",
    "\t\t\t\t\t\t  'FFT Bin Frequency Labels Overall Average', 'Beat Histogram Overall Standard Deviation',\n",
    "\t\t\t\t\t\t  'Log of ConstantQ Overall Average', 'Spectral Centroid Overall Standard Deviation', 'Peak Detection Overall Standard Deviation']\n",
    "\n",
    "# 12/13\n",
    "extra_features_to_drop = ['Derivative of Method of Moments Overall Average', 'Derivative of Running Mean of Method of Moments Overall Average', 'Log of ConstantQ Overall Average']\n",
    "\n",
    "red_marked_features = ['Standard Deviation of Beat Sum Overall Average', 'Area Method of Moments Overall Standard Deviation', 'Derivative of Area Method of Moments Overall Standard Deviation', 'Running Mean of Area Method of Moments Overall Standard Deviation',\n",
    "\t\t\t\t\t   'Standard Deviation of Area Method of Moments Overall Standard Deviation', 'Derivative of Running Mean of Area Method of Moments Overall Standard Deviation', 'Derivative of Standard Deviation of Area Method of Moments Overall Standard Deviation',\n",
    "\t\t\t\t\t   'Standard Deviation of Compactness Overall Average', 'Standard Deviation of Beat Sum Overall Average', 'Standard Deviation of Strongest Frequency Via Zero Crossings Overall Average', 'Standard Deviation of Strongest Frequency Via Spectral Centroid Overall Average',\n",
    "\t\t\t\t\t   'Standard Deviation of Strongest Frequency Via FFT Maximum Overall Average', 'Method of Moments Overall Average', 'Running Mean of Method of Moments Overall Average', 'Standard Deviation of Method of Moments Overall Average',\n",
    "\t\t\t\t\t   'Derivative of Standard Deviation of Method of Moments Overall Average', 'Area Method of Moments Overall Average', 'Derivative of Area Method of Moments Overall Average', 'Running Mean of Area Method of Moments Overall Average',\n",
    "\t\t\t\t\t   'Standard Deviation of Area Method of Moments Overall Average', 'Derivative of Running Mean of Area Method of Moments Overall Average', 'Derivative of Standard Deviation of Area Method of Moments Overall Average',\n",
    "\t\t\t\t\t   ]\n",
    "\n",
    "for f in red_marked_features:\n",
    "\tif f in df_data.columns.tolist():\n",
    "\t\tprint(\"remove this:\", f)\n",
    "\n",
    "# extra_features_to_drop = ['Spectral Centroid Overall Standard Deviation']\n",
    "\n",
    "# removing 'Spectral Centroid Overall Standard Deviation' feature is significantly improving accuracy\n",
    "df_data = df_data.drop(columns=columns_to_drop, axis=1)\n",
    "# df_data = df_data.drop(columns=extra_features_to_drop, axis=1)\n",
    "\n",
    "print(\"Column names:\", df_data.columns.tolist())\n",
    "print(\"MAMAAA:\",  len(df_data.columns.tolist()))\n",
    "\n",
    "df_data = df_data.dropna(axis=1)  # Drop rows with NaN in any column\n",
    "df_data = df_data.loc[:, (df_data != 0).any(axis=0)]  # Drop rows with zero in any column\n",
    "column_list = df_data.columns.values.tolist()\n",
    "##### MODIFY HERE BASED ON YOUR DATA COLOUMNS AND LABEL COLUMNS\n",
    "#Extract x and y from the dataframe\n",
    "X = df_data.iloc[:,0:253].values\n",
    "y = y.values\n",
    "# print(X)\n",
    "# print(y)\n",
    "\n",
    "print(len(X[0]))\n",
    "# print(X[0])\n",
    "X_std = X\n",
    "# Standardize data\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "print(X)\n",
    "print(\"Standard:\")\n",
    "print(X_std)\n",
    "print(len(X_std))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(X_std.shape)\n",
    "\n",
    "# #applying PCA \n",
    "# model = PCA(n_components=60).fit(X_std)\n",
    "# X_pc = model.transform(X_std)\n",
    "\n",
    "# # number of components\n",
    "# n_pcs= model.components_.shape[0]\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_std, y, test_size=0.2, random_state=42)\n",
    "# print(train_x.shape, train_y.shape, test_x.shape, test_y.shape) # check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get the index of the most important feature on EACH component i.e. largest absolute value\n",
    "# # using LIST COMPREHENSION HERE\n",
    "# most_important = [np.abs(model.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "# initial_feature_names = column_list\n",
    "\n",
    "# # get the names\n",
    "# most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "# # using LIST COMPREHENSION HERE AGAIN\n",
    "# dic = {'PC{}'.format(i+1): most_important_names[i] for i in range(n_pcs)}\n",
    "# names_of_imp_features = my_list = list(dic.values())\n",
    "\n",
    "# #Extracting PCA relavent features into a dataframe\n",
    "# pca_df = df_data[names_of_imp_features].copy()\n",
    "\n",
    "# X_pca = pca_df.iloc[:,:].values\n",
    "# X_std_p = StandardScaler().fit_transform(X_pca)\n",
    "# ##### For SOM ######\n",
    "# # train and test split'\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(X_std_p, y, test_size=0.2, random_state=42)\n",
    "# print(train_x.shape, train_y.shape, test_x.shape, test_y.shape) # check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "\n",
    "# Data Normalisation\n",
    "def minmax_scaler(data):\n",
    "  scaler = MinMaxScaler()\n",
    "  scaled = scaler.fit_transform(data)\n",
    "  return scaled\n",
    "\n",
    "# Euclidean distance\n",
    "def e_distance(x,y):\n",
    "  return distance.euclidean(x,y)\n",
    "\n",
    "# Manhattan distance\n",
    "def m_distance(x,y):\n",
    "  return distance.cityblock(x,y)\n",
    "\n",
    "\n",
    "## Degree of Belonging\n",
    "def winning_neuron(data, t, som, num_rows, num_cols):\n",
    "    winner = [0, 0]\n",
    "    shortest_distance = np.sqrt(data.shape[1])  # initialize with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            distance = e_distance(som[row][col], input_data)\n",
    "            if distance < shortest_distance:\n",
    "                shortest_distance = distance\n",
    "                winner = [row, col]\n",
    "    \n",
    "    return winner, shortest_distance\n",
    "\n",
    "def winning_neuron_per_rasa(data, t, som, num_rows, num_cols, label_map, rasa):\n",
    "    winner = [0, 0]\n",
    "    shortest_distance = np.sqrt(data.shape[1])  # initialize with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            if label_map[row][col] == rasa:\n",
    "                distance = e_distance(som[row][col], input_data)\n",
    "                if distance < shortest_distance:\n",
    "                    shortest_distance = distance\n",
    "                    winner = [row, col]\n",
    "    \n",
    "    return winner, shortest_distance\n",
    "\n",
    "def get_shortest_distances_per_rasa(data, t, som, num_rows, num_cols, num_classes, label_map):\n",
    "    df = {}\n",
    "    for rasa in range(1,num_classes+1):\n",
    "        winner, shortest_distance = winning_neuron_per_rasa(data, t, som, num_rows, num_cols, label_map, rasa)\n",
    "        df[rasa] = shortest_distance\n",
    "    winner, shortest_distance = winning_neuron(data, t, som, num_rows, num_cols)\n",
    "    row = winner[0]\n",
    "    col = winner[1]\n",
    "    df[\"Predicted\"] = label_map[row][col]\n",
    "    return label_map[row][col], df\n",
    "\n",
    "\n",
    "# Learning rate and neighbourhood range calculation\n",
    "def decay(step, max_steps,max_learning_rate,max_m_dsitance):\n",
    "  coefficient = 1.0 - (np.float64(step)/max_steps)\n",
    "  learning_rate = coefficient*max_learning_rate\n",
    "  neighbourhood_range = ceil(coefficient * max_m_dsitance)\n",
    "  return learning_rate, neighbourhood_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 105)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  1000\n",
      "Iteration:  2000\n",
      "Iteration:  3000\n",
      "Iteration:  4000\n",
      "Iteration:  5000\n",
      "Iteration:  6000\n",
      "Iteration:  7000\n",
      "Iteration:  8000\n",
      "Iteration:  9000\n",
      "Iteration:  10000\n",
      "Iteration:  11000\n",
      "Iteration:  12000\n",
      "Iteration:  13000\n",
      "Iteration:  14000\n",
      "Iteration:  15000\n",
      "Iteration:  16000\n",
      "Iteration:  17000\n",
      "Iteration:  18000\n",
      "Iteration:  19000\n",
      "Iteration:  20000\n",
      "Iteration:  21000\n",
      "Iteration:  22000\n",
      "Iteration:  23000\n",
      "Iteration:  24000\n",
      "Iteration:  25000\n",
      "Iteration:  26000\n",
      "Iteration:  27000\n",
      "Iteration:  28000\n",
      "Iteration:  29000\n",
      "Iteration:  30000\n",
      "SOM training completed\n"
     ]
    }
   ],
   "source": [
    "#### MODIFY HERE TO CHANGE THE PARAMETS OF SOM\n",
    "\n",
    "# The training may not succeed if the shape of the topological map is not relevant to the distribution of data points in the latent space.\n",
    "# Though we used a square grid in our example, we must design the mapâ€™s formation carefully. \n",
    "# One of the recommendable approaches is to use the ratio of the explained variances from the first two principal components of PCA. \n",
    "# However, if time allows, it is worth trying the different hyperparameters for fine tuning\n",
    "\n",
    "# Parameters\n",
    "num_rows = 12\n",
    "num_cols = 12\n",
    "max_m_distance = 4\n",
    "max_learning_rate = 0.4\n",
    "max_steps = int(3*10e3)\n",
    "\n",
    "train_x_norm = minmax_scaler(train_x)\n",
    "\n",
    "X_norm = minmax_scaler(X_std)\n",
    "\n",
    "print(X_norm.shape)\n",
    "\n",
    "# initialising self-organising map\n",
    "num_dims = X_norm.shape[1] # numnber of dimensions in the input data\n",
    "np.random.seed(40)\n",
    "# som = np.random.random_sample(size=(num_rows, num_cols, num_dims)) # map construction\n",
    "som = np.zeros((num_rows, num_cols, num_dims))\n",
    "# start training iterations\n",
    "for step in range(max_steps):\n",
    "  activation_list = random.sample(range(0,num_rows+num_cols),int((num_rows+num_cols)/1.3))\n",
    "  # print(activation_list)\n",
    "  if (step+1) % 1000 == 0:\n",
    "    print(\"Iteration: \", step+1) # print out the current iteration for every 1k\n",
    "  learning_rate, neighbourhood_range = decay(step, max_steps,max_learning_rate,max_m_distance)\n",
    "\n",
    "  t = np.random.randint(0,high=X_norm.shape[0]) # random index of traing data\n",
    "  winner,shortest_distance = winning_neuron(X_norm, t, som, num_rows, num_cols)\n",
    "  for row in range(num_rows):\n",
    "    for col in range(num_cols):\n",
    "      # if (row+col) in activation_list:\n",
    "\n",
    "      #   # print(\"hi\")\n",
    "      #   continue\n",
    "\n",
    "      if m_distance([row,col],winner) <= neighbourhood_range:\n",
    "        som[row][col] += learning_rate*(X_norm[t]-som[row][col]) # update neighbour's weight\n",
    "\n",
    "print(\"SOM training completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 2 4 2 1 2 1 2 3 2 2 3]\n",
      " [2 4 2 4 2 2 2 2 2 2 2 2]\n",
      " [4 2 4 2 2 2 4 2 2 1 2 2]\n",
      " [2 2 2 2 2 4 2 2 1 2 1 2]\n",
      " [2 4 2 3 2 2 2 3 2 2 2 1]\n",
      " [3 2 2 2 2 2 3 2 1 2 2 2]\n",
      " [3 2 2 2 2 2 2 4 2 1 2 2]\n",
      " [2 3 2 2 2 1 2 2 3 2 1 2]\n",
      " [1 2 4 2 2 2 1 3 2 2 1 2]\n",
      " [2 4 2 2 2 1 2 2 3 2 2 1]\n",
      " [2 2 3 2 3 2 4 2 2 2 2 2]\n",
      " [3 2 2 4 2 4 2 3 2 1 2 1]]\n",
      "[[[2.29385862e-01 8.12471791e-02 4.92898670e-01 ... 7.75107698e-01\n",
      "   8.70449957e-01 0.00000000e+00]\n",
      "  [2.75156024e-01 1.25455693e-01 8.15413556e-01 ... 5.60069083e-01\n",
      "   8.37586647e-01 0.00000000e+00]\n",
      "  [1.32588828e-01 2.74818257e-02 8.90589554e-01 ... 3.67426322e-01\n",
      "   8.79324208e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [2.85309173e-02 3.78384053e-03 3.17957672e-01 ... 2.67777771e-01\n",
      "   8.44339563e-01 0.00000000e+00]\n",
      "  [1.36269090e-01 6.98362052e-02 3.20939040e-01 ... 2.35206476e-01\n",
      "   3.37474374e-01 0.00000000e+00]\n",
      "  [1.81985903e-01 8.50569605e-02 3.78085373e-01 ... 1.66266999e-01\n",
      "   7.82497754e-04 0.00000000e+00]]\n",
      "\n",
      " [[4.63530723e-01 2.20566256e-01 7.07045628e-01 ... 7.67929151e-01\n",
      "   8.39132893e-01 0.00000000e+00]\n",
      "  [4.47781923e-01 2.54214630e-01 9.98960827e-01 ... 5.73522987e-01\n",
      "   7.71925329e-01 0.00000000e+00]\n",
      "  [3.84602889e-01 2.07917604e-01 8.97923956e-01 ... 5.45523786e-01\n",
      "   8.26837558e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [4.81042464e-02 2.42588942e-02 2.78823047e-01 ... 4.13692984e-01\n",
      "   8.01221307e-01 0.00000000e+00]\n",
      "  [8.36054319e-02 5.22151490e-02 2.55468433e-01 ... 3.14784503e-01\n",
      "   7.24311055e-01 0.00000000e+00]\n",
      "  [9.17333209e-02 4.73550936e-02 2.25591147e-01 ... 2.11148330e-01\n",
      "   4.95126126e-01 0.00000000e+00]]\n",
      "\n",
      " [[6.56494008e-01 2.93269024e-01 5.84545054e-01 ... 9.52047222e-01\n",
      "   8.81195237e-01 0.00000000e+00]\n",
      "  [5.03536007e-01 2.49648676e-01 8.00441872e-01 ... 6.72939320e-01\n",
      "   8.38321933e-01 0.00000000e+00]\n",
      "  [3.75351097e-01 1.86946527e-01 8.28201046e-01 ... 4.38237809e-01\n",
      "   8.66775415e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [1.78150291e-02 5.79610391e-04 2.96238694e-01 ... 4.87455732e-01\n",
      "   8.65100786e-01 0.00000000e+00]\n",
      "  [2.78970685e-02 1.27035190e-02 1.96841138e-01 ... 3.19827062e-01\n",
      "   8.04781440e-01 0.00000000e+00]\n",
      "  [1.79017284e-02 1.02114013e-02 6.92119778e-02 ... 1.75097331e-01\n",
      "   7.60574764e-01 0.00000000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[2.71447065e-01 1.70481417e-01 4.59786770e-01 ... 5.98492918e-01\n",
      "   8.55910980e-01 0.00000000e+00]\n",
      "  [1.30065220e-01 3.14445812e-02 5.21369013e-01 ... 9.95499483e-01\n",
      "   8.49432096e-01 0.00000000e+00]\n",
      "  [2.89924642e-01 1.60682009e-01 4.29808595e-01 ... 7.67273760e-01\n",
      "   8.35268396e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [2.69585398e-01 1.53598014e-01 2.02133223e-01 ... 6.24486272e-01\n",
      "   8.12068337e-01 0.00000000e+00]\n",
      "  [2.61078615e-01 1.70340231e-01 1.99516481e-01 ... 4.26838589e-01\n",
      "   8.53994163e-01 0.00000000e+00]\n",
      "  [2.44222268e-01 1.95020030e-01 3.24434852e-02 ... 3.11594322e-01\n",
      "   8.61340504e-01 0.00000000e+00]]\n",
      "\n",
      " [[1.16278910e-01 7.07430707e-02 3.40095151e-01 ... 3.30179574e-01\n",
      "   8.41860995e-01 0.00000000e+00]\n",
      "  [1.53458388e-01 5.01704798e-02 4.10242032e-01 ... 9.77461465e-01\n",
      "   8.18141720e-01 0.00000000e+00]\n",
      "  [1.74498439e-01 6.72501310e-02 3.16983771e-01 ... 9.58712283e-01\n",
      "   7.92197076e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [2.12751567e-01 1.14955294e-01 2.49041940e-01 ... 4.14820321e-01\n",
      "   8.55212254e-01 0.00000000e+00]\n",
      "  [3.07942911e-01 1.87316832e-01 2.56563919e-01 ... 3.35270200e-01\n",
      "   8.57617899e-01 0.00000000e+00]\n",
      "  [2.82082327e-01 2.31495551e-01 1.33202693e-01 ... 3.72460643e-01\n",
      "   8.63493401e-01 0.00000000e+00]]\n",
      "\n",
      " [[1.16340046e-01 7.10181229e-02 3.39320340e-01 ... 3.27161263e-01\n",
      "   8.41854075e-01 0.00000000e+00]\n",
      "  [1.16229591e-01 7.06880387e-02 3.40078323e-01 ... 3.30395955e-01\n",
      "   8.41838192e-01 0.00000000e+00]\n",
      "  [2.22524763e-01 1.00480227e-01 2.78853489e-01 ... 7.98092890e-01\n",
      "   8.30188544e-01 0.00000000e+00]\n",
      "  ...\n",
      "  [1.63763981e-01 6.19432929e-02 2.90463462e-01 ... 4.95539024e-01\n",
      "   8.53700843e-01 0.00000000e+00]\n",
      "  [2.39929760e-01 1.81957209e-01 1.94666528e-01 ... 4.28819340e-01\n",
      "   8.60756101e-01 0.00000000e+00]\n",
      "  [2.88243335e-01 2.96804535e-01 1.03018378e-01 ... 4.50564547e-01\n",
      "   8.70166968e-01 0.00000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "# collecting labels\n",
    "\n",
    "label_data = y\n",
    "map = np.empty(shape=(num_rows, num_cols), dtype=object)\n",
    "\n",
    "for row in range(num_rows):\n",
    "  for col in range(num_cols):\n",
    "    map[row][col] = [] # empty list to store the label\n",
    "\n",
    "for t in range(X_norm.shape[0]):\n",
    "  if (t+1) % 1000 == 0:\n",
    "    print(\"sample data: \", t+1)\n",
    "  winner, shortest_distance = winning_neuron(X_norm, t, som, num_rows, num_cols)\n",
    "  map[winner[0]][winner[1]].append(label_data[t]) # label of winning neuron\n",
    "\n",
    "  # construct label map\n",
    "label_map = np.zeros(shape=(num_rows, num_cols),dtype=np.int64)\n",
    "for row in range(num_rows):\n",
    "  for col in range(num_cols):\n",
    "    label_list = map[row][col]\n",
    "    if len(label_list)==0:\n",
    "      label = 2\n",
    "    else:\n",
    "      label = max(label_list, key=label_list.count)\n",
    "    label_map[row][col] = label\n",
    "\n",
    "title = ('Iteration ' + str(max_steps))\n",
    "# for rasa data\n",
    "cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:orange','tab:gray'])\n",
    "# for indina data\n",
    "# cmap = colors.ListedColormap(['tab:green', 'tab:red', 'tab:orange','tab:gray','tab:blue','tab:cyan','tab:white','tab:yellow','tab:black','tab:violet'])\n",
    "plt.imshow(label_map, cmap=cmap)\n",
    "plt.colorbar()\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "print(label_map)\n",
    "print(som)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 / 62\n",
      "Accuracy:  0.9838709677419355\n"
     ]
    }
   ],
   "source": [
    "data = minmax_scaler(train_x) # normalisation\n",
    "X_norm = minmax_scaler(X_std)\n",
    "winner_labels = []\n",
    "df = []\n",
    "num_classes = 4\n",
    "rasas = [\"KARUNA\", \"SHANTA\", \"SHRINGAR\", \"VEERA\"]\n",
    "for t in range(X_norm.shape[0]):\n",
    "\twinner, rasa_df = get_shortest_distances_per_rasa(X_norm, t, som, num_rows, num_cols, num_classes, label_map)\n",
    "\t# print(winner)\n",
    "\twinner_labels.append(winner)\n",
    "\trasa_df[\"REAL\"] = y[t]\n",
    "\tdf.append(rasa_df)\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"final_classes_per_rasa.csv\", index=False)\n",
    "\n",
    "count=0\n",
    "for i in range(len(X_norm)):\n",
    "\tif y[i] == winner_labels[i]:\n",
    "\t\tcount+=1\n",
    "print(count, \"/\", len(X_norm))\n",
    "print(\"Accuracy: \",accuracy_score(y, np.array(winner_labels)))\n",
    "# print(\"Accuracy: \",accuracy_score(train_y, np.array(winner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{6.391761038947015: 1, 6.485865250545851: 1, 6.487572408735584: 2, 6.496301391592073: 2} xxx 3\n",
      "{6.012919969669135: 1, 6.044867087601515: 2, 6.046194949394221: 1, 6.055632548746098: 2} xxx 3\n",
      "60\n",
      "{6.391761038947015: 1, 6.485865250545851: 1, 6.487572408735584: 2, 6.496301391592073: 2} xxx 3\n",
      "{6.012919969669135: 1, 6.044867087601515: 2, 6.046194949394221: 1, 6.055632548746098: 2} xxx 3\n",
      "60\n",
      "Accuracy based on binary occurrence: 60 / 62 -> 96.7741935483871\n",
      "{1: 2, 2: 2}\n",
      "yes {'Rasa': 1, 'KARUNA': 0.5, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.7386147432208323', 'SHANTA': '0.9242764143932359', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 2, 2: 1, 3: 1}\n",
      "yes {'Rasa': 1, 'KARUNA': 0.5, 'SHANTA': 0.25, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "noo {'Rasa': 1, 'KARUNA': '1.5114189517847618', 'SHANTA': '1.2122534693742153', 'SHRINGAR': '1.505399383707831', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.003971394954029547', 'SHANTA': '2.4472878339875437', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 3: 1, 2: 2}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.407735218583825', 'SHANTA': '0.5856906728809215', 'SHRINGAR': '0.41793335407002774', 'VEERA': '-'}\n",
      "{1: 2, 2: 2}\n",
      "yes {'Rasa': 1, 'KARUNA': 0.5, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.9383290829381121', 'SHANTA': '1.0819458288591004', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 2, 3: 1}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.4982801102774508', 'SHANTA': '0.7184438708812926', 'SHRINGAR': '1.0459245038681806', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.013687751389203823', 'SHANTA': '0.8346945404812007', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.04018280965629709', 'SHANTA': '0.8665056936074917', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.025263021434910615', 'SHANTA': '0.8220474621957312', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 2, 4: 1}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.019686434418993422', 'SHANTA': '0.9108071248776228', 'SHRINGAR': '-', 'VEERA': '0.8621431671978897'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.0014981808037610688', 'SHANTA': '1.1647446779306148', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 2, 2: 2}\n",
      "yes {'Rasa': 1, 'KARUNA': 0.5, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.7398823858336221', 'SHANTA': '0.7833074716345213', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.6128860412664473', 'SHANTA': '1.0644717474437446', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.0018764199685964054', 'SHANTA': '1.341406426799103', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.002364212548406589', 'SHANTA': '1.9413168738140774', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "noo {'Rasa': 1, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.21864529337708863', 'SHANTA': '0.9020583908764407', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 2, 2: 2}\n",
      "yes {'Rasa': 1, 'KARUNA': 0.5, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 1, 'KARUNA': '0.5317749852052066', 'SHANTA': '0.7325201942190643', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.8095844019320316', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.110211811375523', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.8773920681115195', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.7853623319567902', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{1: 1, 2: 3}\n",
      "yes {'Rasa': 2, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "noo {'Rasa': 2, 'KARUNA': '0.5301382622392865', 'SHANTA': '0.9775525765387663', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.6985874494654418', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.8418891893515333', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 2, 1: 1, 3: 1}\n",
      "yes {'Rasa': 2, 'KARUNA': 0.25, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "noo {'Rasa': 2, 'KARUNA': '0.4814106769442392', 'SHANTA': '0.7726645419324049', 'SHRINGAR': '0.5332300228799706', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.4405056894337265', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.4596355070587261', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 3, 1: 1}\n",
      "yes {'Rasa': 2, 'KARUNA': 0.25, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '0.7193915558103836', 'SHANTA': '0.6607347682092007', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.2410700023432122', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.2323624409120906', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '1.043511907596673', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{2: 4}\n",
      "yes {'Rasa': 2, 'KARUNA': 0, 'SHANTA': 1.0, 'SHRINGAR': 0, 'VEERA': 0}\n",
      "yes {'Rasa': 2, 'KARUNA': '-', 'SHANTA': '0.8522845085007293', 'SHRINGAR': '-', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.9289141569260031', 'SHRINGAR': '0.0005467731298693598', 'VEERA': '-'}\n",
      "{3: 2, 2: 2}\n",
      "yes {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.5, 'SHRINGAR': 0.5, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.8852847339927925', 'SHRINGAR': '0.48467923033711663', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.9209893512964494', 'SHRINGAR': '0.01644085504685954', 'VEERA': '-'}\n",
      "{3: 1, 2: 2, 4: 1}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0.25}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.8891309548874422', 'SHRINGAR': '0.5603374453495717', 'VEERA': '0.8393376040866212'}\n",
      "{3: 2, 2: 2}\n",
      "yes {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.5, 'SHRINGAR': 0.5, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '1.2246584242689853', 'SHRINGAR': '0.6684455474735134', 'VEERA': '-'}\n",
      "{3: 1, 1: 1, 2: 2}\n",
      "noo {'Rasa': 3, 'KARUNA': 0.25, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '0.35190107561057365', 'SHANTA': '0.7599159608683074', 'SHRINGAR': '0.3411819561574606', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '2.6099159716527223', 'SHRINGAR': '0.002820545967540535', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.9845854465138651', 'SHRINGAR': '0.022880088549871804', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.9897248847525204', 'SHRINGAR': '0.002029256351985395', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.6690693094712894', 'SHRINGAR': '0.3850285714781471', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '1.3144370228893358', 'SHRINGAR': '0.0042755360511411026', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.943268990475412', 'SHRINGAR': '0.011811995338693882', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '1.6819945023869678', 'SHRINGAR': '0.0010998789237756511', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '1.0316605900271374', 'SHRINGAR': '0.001670219730477065', 'VEERA': '-'}\n",
      "{3: 1, 2: 3}\n",
      "noo {'Rasa': 3, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0.25, 'VEERA': 0}\n",
      "yes {'Rasa': 3, 'KARUNA': '-', 'SHANTA': '0.7825964351094655', 'SHRINGAR': '0.010624121201770122', 'VEERA': '-'}\n",
      "{4: 2, 2: 2}\n",
      "yes {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.5, 'SHRINGAR': 0, 'VEERA': 0.5}\n",
      "noo {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.7059108993918457', 'SHRINGAR': '-', 'VEERA': '1.9681772121014176'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.4181005037645236', 'SHRINGAR': '-', 'VEERA': '0.006473339633113064'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.084356435025505', 'SHRINGAR': '-', 'VEERA': '0.007376956441654371'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.9599730484986613', 'SHRINGAR': '-', 'VEERA': '0.002517900401564528'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.9397984902327814', 'SHRINGAR': '-', 'VEERA': '0.0006002113580330144'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '0.8373446050137093', 'SHRINGAR': '-', 'VEERA': '0.015955572615542465'}\n",
      "{4: 1, 2: 2, 3: 1}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.5, 'SHRINGAR': 0.25, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '0.8511485441790724', 'SHRINGAR': '0.888978958302585', 'VEERA': '0.434479841451991'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '0.8898643064819861', 'SHRINGAR': '-', 'VEERA': '0.0006238422172791065'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.1989724930127874', 'SHRINGAR': '-', 'VEERA': '0.00453445090058704'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.1367310678324092', 'SHRINGAR': '-', 'VEERA': '0.0007624092275577318'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.2130344465986755', 'SHRINGAR': '-', 'VEERA': '0.211022654986389'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.6527307035609513', 'SHRINGAR': '-', 'VEERA': '0.0019806519961706823'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.6204021553372452', 'SHRINGAR': '-', 'VEERA': '0.005914234683637691'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.5224497601157765', 'SHRINGAR': '-', 'VEERA': '0.017016446417389114'}\n",
      "{4: 1, 2: 3}\n",
      "noo {'Rasa': 4, 'KARUNA': 0, 'SHANTA': 0.75, 'SHRINGAR': 0, 'VEERA': 0.25}\n",
      "yes {'Rasa': 4, 'KARUNA': '-', 'SHANTA': '1.2714196697107076', 'SHRINGAR': '-', 'VEERA': '0.001613448852693406'}\n",
      "23\n",
      "62\n",
      "Accuracy based on distance: 58/62 -> 93.54838709677419\n",
      "Accuracy based on belongingness: 23/62 -> 37.096774193548384\n",
      "overall accuracy: 0.6532258064516129\n"
     ]
    }
   ],
   "source": [
    "## Degree of Belonging\n",
    "def winning_neuron(data, t, som, num_rows, num_cols):\n",
    "    winner = [0, 0]\n",
    "    shortest_distance = np.sqrt(data.shape[1])  # initialize with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            distance = e_distance(som[row][col], input_data)\n",
    "            if distance < shortest_distance:\n",
    "                shortest_distance = distance\n",
    "                winner = [row, col]\n",
    "    \n",
    "    return winner, shortest_distance\n",
    "\n",
    "\n",
    "def winning_neuron_per_rasa(data, t, som, num_rows, num_cols, rasa):\n",
    "    winner = [0, 0]\n",
    "    shortest_distance = np.sqrt(data.shape[1])  # initialize with max distance\n",
    "    input_data = data[t]\n",
    "    for row in range(num_rows):\n",
    "        for col in range(num_cols):\n",
    "            if label_map[row][col] == rasa:\n",
    "                distance = e_distance(som[row][col], input_data)\n",
    "                if distance < shortest_distance:\n",
    "                    shortest_distance = distance\n",
    "                    winner = [row, col]\n",
    "    \n",
    "    return winner, shortest_distance\n",
    "\n",
    "def get_bmu(data_point,som,feature_len,label_map):\n",
    "    length = len(som)\n",
    "    degree_of_bel = {}\n",
    "    distances = []\n",
    "\n",
    "    for l in range(feature_len):\n",
    "        shortest_distance = 100000000000\n",
    "        for i in range(length):\n",
    "            for j in range(length):\n",
    "                distance = e_distance(som[i][j], data_point)\n",
    "                # print(distance)\n",
    "                if distance in distances : continue\n",
    "                if distance < shortest_distance: \n",
    "                    shortest_distance = distance\n",
    "                    winner = [i,j]\n",
    "                    if l == 0 : bmu = som[i][j]\n",
    "        # print(label_map[winner])\n",
    "        degree_of_bel[shortest_distance] = label_map[winner[0]][winner[1]]\n",
    "        distances.append(shortest_distance)\n",
    "    return degree_of_bel, bmu,distances\n",
    "\n",
    "# degree_of_bel, bmu,distances = get_bmu(train_x_norm[1],som,20,label_map)\n",
    "# print(\"Degree of belonging for 4 least: \",degree_of_bel,\"BMU value: \", bmu)\n",
    "\n",
    "def accuracy_score_dct(labels, train_y):\n",
    "    length = len(train_y)\n",
    "    correct = 0\n",
    "    # print(labels)\n",
    "    # print(length)\n",
    "    for i in range(length):\n",
    "        \n",
    "        degree_dict = labels[i]\n",
    "        # print(\"train_y[i]:\",train_y[i])\n",
    "        # print(\"degreeeee:\", degree_dict)\n",
    "        if train_y[i] in degree_dict.values():\n",
    "            correct+=1\n",
    "        else:\n",
    "            print(labels[i], \"xxx\", train_y[i])\n",
    "\n",
    "    print(correct)\n",
    "    accuracy  = correct/length *100\n",
    "    return accuracy\n",
    "# labels = [{0.47805698154643694: 3, 0.5279256320016263: 1, 0.5922260546574805: 3, 0.6070726811186519: 1}]\n",
    "# # train_y = [1]\n",
    "# print(accuracy_score_dct(labels,train_y))\n",
    "\n",
    "def belonging(lables):\n",
    "    # print(lables)\n",
    "    belonging = [0,0,0,0]\n",
    "    res = dict(Counter(lables.values()))\n",
    "    for i in range(4):\n",
    "        if i+1 in res:\n",
    "            belonging[i] = res[i+1]/4\n",
    "            # belonging[i] = list(lables.keys())[i]\n",
    "    print(res)\n",
    "    return belonging\n",
    "\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "# print(\"Scaled: \", X_std)\n",
    "X_norm = minmax_scaler(X_std)\n",
    "\n",
    "test_x_norm = minmax_scaler(test_x)\n",
    "lables = []\n",
    "for i in range(len(X_std)):\n",
    "    ### MODIY NUMBER LABELS ACCORDING TO THE NUMBER OF CLASSES IN YOUR CSV\n",
    "    num_labels = 4\n",
    "    d,_,_ = get_bmu(X_std[i],som,num_labels,label_map)\n",
    "    lables.append(d)\n",
    "accuracy =accuracy_score_dct(lables,y)\n",
    "print(f\"Accuracy based on binary occurrence: {int((accuracy/100)*len(y))} / {len(y)} ->\", accuracy_score_dct(lables,y))\n",
    "\n",
    "# Make a dataframe of probablities from the label map\n",
    "\n",
    "occurence_df = []\n",
    "distance_df = []\n",
    "rasa_percent = {1:0,2:0,3:0,4:0}\n",
    "X_norm = minmax_scaler(X_std)\n",
    "correct = 0\n",
    "distance_correct = 0\n",
    "for i in range(len(X_norm)):\n",
    "#### MODIFY HERE TO CHANGE THE DEPTH OF DEGREE OF BELONGING \n",
    "    num_rel_features = 4\n",
    "    d,_,_ = get_bmu(X_norm[i],som,num_rel_features,label_map)\n",
    "    # data = {9.030693919535057: 4, 9.133194158572492: 4, 9.209343639190228: 1, 9.227512411079285: 1}\n",
    "\n",
    "    # Step 1: Create a list of tuples\n",
    "    sorted_data = sorted(d.items(), key=lambda x: x[1])\n",
    "\n",
    "    # Step 2: Initialize an empty list to store the result\n",
    "    result_list = [\"-\"] * 4\n",
    "\n",
    "    # Step 3: Iterate through the sorted list and create the result list\n",
    "    for key, value in sorted_data:\n",
    "        result_list[value - 1] = str(key)\n",
    "    # print(result_list)\n",
    "    \n",
    "    blgn = belonging(d)\n",
    "    x = [99999999 if val == \"-\" else float(val) for val in result_list]\n",
    "    if max(blgn) == blgn[y[i]-1]:\n",
    "        correct+=1\n",
    "        print(\"yes\", {\"Rasa\": y[i],\"KARUNA\":blgn[0],\"SHANTA\":blgn[1],\"SHRINGAR\":blgn[2],\"VEERA\":blgn[3]})\n",
    "    else:\n",
    "        print(\"noo\", {\"Rasa\": y[i],\"KARUNA\":blgn[0],\"SHANTA\":blgn[1],\"SHRINGAR\":blgn[2],\"VEERA\":blgn[3]})\n",
    "    occurence_df.append({\"Rasa\": y[i],\"KARUNA\":blgn[0],\"SHANTA\":blgn[1],\"SHRINGAR\":blgn[2],\"VEERA\":blgn[3]})\n",
    "\n",
    "    if x.index(min(x)) == y[i]-1:\n",
    "        distance_correct+=1\n",
    "        print(\"yes\", {\"Rasa\": y[i],\"KARUNA\":result_list[0],\"SHANTA\":result_list[1],\"SHRINGAR\":result_list[2],\"VEERA\":result_list[3]})\n",
    "    else:\n",
    "        print(\"noo\", {\"Rasa\": y[i],\"KARUNA\":result_list[0],\"SHANTA\":result_list[1],\"SHRINGAR\":result_list[2],\"VEERA\":result_list[3]})\n",
    "    distance_df.append({\"Rasa\": y[i],\"KARUNA\":result_list[0],\"SHANTA\":result_list[1],\"SHRINGAR\":result_list[2],\"VEERA\":result_list[3]})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "occurence_df = pd.DataFrame(occurence_df)\n",
    "distance_df = pd.DataFrame(distance_df)\n",
    "print(correct)\n",
    "print(len(y))\n",
    "print(f\"Accuracy based on distance: {distance_correct}/{len(y)} ->\", distance_correct/len(y) * 100)\n",
    "print(f\"Accuracy based on belongingness: {correct}/{len(y)} ->\", correct/len(y) * 100)\n",
    "print(f\"overall accuracy: {((distance_correct/len(y)) + (correct/len(y))) / 2}\")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "occurence_df.to_csv(\"deg_of_bel_occurence.csv\", index=False)\n",
    "distance_df.to_csv(\"distance_deg_of_bel.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
